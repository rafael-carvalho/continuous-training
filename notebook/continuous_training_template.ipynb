{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This tutorial demonstrates how to trigger a Vertex Pipeline:\n",
    "- Via storage upload\n",
    "- Directly via the API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Costs \n",
    "\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Artifact Registry\n",
    "* BigQuery\n",
    "* Cloud Resource Manager\n",
    "* Cloud AI Companion\n",
    "* Cloud Run Functions\n",
    "* IAM\n",
    "* EventArc\n",
    "* Cloud Build\n",
    "* Google Cloud Storage\n",
    "* Compute Engine\n",
    "* Dataform\n",
    "* PubSub\n",
    "* Vertex AI\n",
    "\n",
    "Other API's may have been enabled and may not be included in this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Install the required libraries\n",
    "# ! pip install google-cloud-aiplatform "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart runtime (Colab only)\n",
    "\n",
    "To use the newly installed packages, you must restart the runtime on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    #import IPython\n",
    "\n",
    "    #app = IPython.Application.instance()\n",
    "    #app.kernel.do_shutdown(True)\n",
    "    print(\"Skipping the restart\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "Authenticate your environment on Google Colab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Imports\n",
    "from google.cloud import aiplatform as vertex\n",
    "from datetime import datetime\n",
    "from google.auth import default\n",
    "from google.auth.transport.requests import AuthorizedSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Google Cloud project information\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project. Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Set the variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigger the pipeline directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Setup the Pipeline Parameters\n",
    "\n",
    "display_name = f\"notebook_{datetime.now().isoformat()}\"\n",
    "persistent_resource_id = PERSISTENT_RESOURCE_NAME.split(\"/\")[-1] if PERSISTENT_RESOURCE_NAME else None\n",
    "pipeline_root = f\"gs://{BUCKET}/pipeline_triggered_via_notebook/{display_name}\"\n",
    "model_artifact_dir = f\"{pipeline_root}/model/\"\n",
    "\n",
    "pipeline_parameters = {\n",
    "\"training_job_display_name\": f\"training_{display_name}\",\n",
    "  \"bq_training_data_uri\": BQ_TRAINING_DATA_URI,\n",
    "  \"existing_model\": EXISTING_MODEL,\n",
    "  \"parent_model_resource_name\": PARENT_MODEL_RESOURCE_NAME,\n",
    "  \"pipeline_root\": pipeline_root,\n",
    "  \"prediction_container_image_uri\": PREDICTION_CONTAINER_IMAGE_URI,\n",
    "  \"production_endpoint_id\": PRODUCTION_ENDPOINT_ID,\n",
    "  \"tensorboard\": TENSORBOARD,\n",
    "  \"service_account\": RUNNER_SERVICE_ACCOUNT_EMAIL,\n",
    "  \"persistent_resource_id\": persistent_resource_id,\n",
    "  \"model_artifact_dir\": model_artifact_dir,\n",
    "  \"worker_pool_specs\": [\n",
    "    {\n",
    "      \"machine_spec\": {\n",
    "        \"machine_type\": MACHINE_TYPE\n",
    "      },\n",
    "      \"replica_count\": 1,\n",
    "      \"container_spec\": {\n",
    "        \"image_uri\": TRAINING_CONTAINER_IMAGE_URI,\n",
    "        \"command\": [\n",
    "          \"python\",\n",
    "          \"train.py\"\n",
    "        ],\n",
    "        \"args\": [\n",
    "          \"--data_path\",\n",
    "          BQ_TRAINING_DATA_URI,\n",
    "          \"--model_checkpoint_dir\",\n",
    "          MODEL_CHECKPOINT_DIR\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex.init(project=PROJECT_ID, location=REGION, staging_bucket=pipeline_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Helper functions\n",
    "\n",
    "def _form_request(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    pipeline_job: vertex.PipelineJob,\n",
    "    service_account: str,\n",
    "    persistent_resource_name: str,\n",
    ") -> tuple[str, dict, dict]:\n",
    "    \"\"\"Forms the API request for pipeline job submission.\"\"\"\n",
    "\n",
    "    endpoint = f\"https://{location}-aiplatform.googleapis.com/v1beta1/projects/{project_id}/locations/{location}/pipelineJobs\"\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    pipeline_spec = pipeline_job.to_dict()\n",
    "    pipeline_spec[\"serviceAccount\"] = service_account\n",
    "    pipeline_spec[\"runtimeConfig\"][\"defaultRuntime\"] = {\n",
    "        \"persistentResourceRuntimeDetail\": {\"persistentResourceName\": persistent_resource_name}\n",
    "    }\n",
    "\n",
    "    return endpoint, headers, pipeline_spec\n",
    "\n",
    "\n",
    "def submit_pipeline_job(\n",
    "    project_id: str,\n",
    "    location: str,\n",
    "    pipeline_parameters: dict,\n",
    "    pipeline_template_path: str,\n",
    "    service_account: str,\n",
    "    pipeline_root: str,\n",
    "    persistent_resource_name: str,\n",
    "    display_name: str = display_name,  # Provide a default display name\n",
    "    enable_caching: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"Submits a Vertex AI pipeline job.\n",
    "\n",
    "    Args:\n",
    "        project_id: Project ID.\n",
    "        location: Region of the pipeline job.\n",
    "        pipeline_parameters: Pipeline parameters.\n",
    "        pipeline_template_path: Artifact Registry URI or GCS path for the compiled pipeline.\n",
    "        service_account: Service account email.\n",
    "        pipeline_root: GCS path for the pipeline root directory.\n",
    "        persistent_resource_name: Name of the persistent resource.\n",
    "        display_name: Display name for the pipeline job.\n",
    "        enable_caching: Enable caching.\n",
    "\n",
    "    Returns:\n",
    "        The pipeline job resource name.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Creating Pipeline Job with display_name={display_name}\")\n",
    "\n",
    "    pipeline_job = vertex.PipelineJob(\n",
    "        display_name=display_name,\n",
    "        parameter_values=pipeline_parameters,\n",
    "        enable_caching=enable_caching,\n",
    "        template_path=pipeline_template_path,\n",
    "        pipeline_root=pipeline_root,\n",
    "    )\n",
    "\n",
    "    endpoint, headers, pipeline_spec = _form_request(\n",
    "        project_id=project_id,\n",
    "        location=location,\n",
    "        pipeline_job=pipeline_job,\n",
    "        service_account=service_account,\n",
    "        persistent_resource_name=persistent_resource_name,\n",
    "    )\n",
    "\n",
    "    credentials, _ = default()  # No need to retrieve project_id again\n",
    "    session = AuthorizedSession(credentials)\n",
    "\n",
    "    response = session.post(endpoint, headers=headers, json=pipeline_spec)  # Use json parameter directly\n",
    "    response.raise_for_status() # Raise an exception for bad status codes\n",
    "\n",
    "    response_json = response.json()\n",
    "    pipeline_job_resource_name = response_json[\"name\"]\n",
    "\n",
    "\n",
    "    print(f\"Pipeline Job submitted: {pipeline_job_resource_name}\")\n",
    "    # Constructing the console link\n",
    "    run_id = pipeline_job_resource_name.split('/')[-1]\n",
    "    console_link = f\"https://console.cloud.google.com/vertex-ai/pipelines/locations/{location}/runs/{run_id}?project={project_id}\"\n",
    "    print(f\"Console link: {console_link}\")\n",
    "\n",
    "\n",
    "    return pipeline_job_resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigger via File Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigger the pipeline via file upload\n",
    "# Once you upload a file to the trigger bucket, a Cloud Run Function will detect the new file and will kick off the flow\n",
    "# It will create a new BQ Table with the data that was uploaded, then it will send a Pub/Sub message to a topic with all \n",
    "# the required pipeline information\n",
    "# Another Cloud Run Function will be triggered, which will then instantiate the pipeline run.\n",
    "\n",
    "! gsutil cp $GCS_SAMPLE_TRAINING_DATA_URI gs://$TRIGGER_BUCKET/\n",
    "\n",
    "print(\"Go to the link below to see the new pipeline run\")\n",
    "print(f\"https://console.cloud.google.com/vertex-ai/pipelines/runs?project={PROJECT_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigger the pipeline via API\n",
    "\n",
    "submit_pipeline_job(\n",
    "    project_id = PROJECT_ID,\n",
    "    location = REGION,\n",
    "    pipeline_parameters=pipeline_parameters,\n",
    "    pipeline_template_path=PIPELINE_TEMPLATE_PATH,\n",
    "    service_account=RUNNER_SERVICE_ACCOUNT_EMAIL,\n",
    "    pipeline_root=pipeline_root,\n",
    "    persistent_resource_name=PERSISTENT_RESOURCE_NAME,\n",
    "    display_name = display_name,\n",
    "    enable_caching = False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
